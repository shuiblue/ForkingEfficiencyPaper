---
title: "Forks models"
output:
  html_document:
    theme: flatly
    fig_height: 3
    fig_width: 4
---

```{r, include=FALSE}
library(car) #vif
library(pscl) #pR2

source("helpers.R")
library(texreg)
library(xtable)
library(ggplot2)
library(stringr)

REWRITE_MODELS = FALSE
```

### Load data from csv
```{r}
project_data = read.csv(file="project_data.csv", header=TRUE, sep=",")
nrow(project_data) # projects in project-level data
```

Look for outliers in project-level data

```{r}
# Not shown
```


```{r eval=FALSE, collapse=TRUE, include=FALSE}
summary(project_data$NumForks)
hist(project_data[project_data$num_forks < 25000,]$num_forks)
hist(log(project_data[project_data$num_forks < 25000,]$num_forks+1))
hist(project_data[project_data$num_forks < 25000,]$NumForks)

hist(log(project_data[project_data$size < 1500000,]$size))
hist(project_data[project_data$size < 1500000,]$Size)

hist(project_data$ProjectAge)

summary(project_data$median_submitPR_exprience)
hist(project_data$median_submitPR_exprience)
summary(project_data$MedianSubmitterExperience)
hist(project_data$MedianSubmitterExperience)
hist(log(project_data$MedianSubmitterExperience + 1))
table(project_data$MedianSubmitterExperience > 0) # MedianSubmitterExperience looks better as a binary variable

summary(project_data$hotness_mean_external_correct)
hist(project_data$hotness_mean_external_correct)
table(project_data$hotness_mean_external_correct > 0)
table(project_data$hotness_mean_external_correct > 50)
hist(log(project_data[project_data$hotness_mean_external_correct <= 50,]$hotness_mean_external_correct+1))
hist(project_data[project_data$hotness_mean_external_correct <= 50,]$PRHotness)
# hist(project_data$hotness_median_external_correct)
# summary(project_data$hotness_median_external_correct)
# table(project_data$hotness_median_external_correct > 0)
# table(project_data$hotness_median_external_correct > 25)
# hist(log(project_data[project_data$hotness_median_external_correct<=25,]$hotness_median_external_correct + 1))

hist(project_data$ratio_PR_withTest_external)
summary(project_data$ratio_PR_withTest_external)
hist(project_data[project_data$ratio_PR_withTest_external <= 0.7,]$ratio_PR_withTest_external)
hist(log(project_data[project_data$ratio_PR_withTest_external <= 0.7,]$ratio_PR_withTest_external+1))
hist(project_data[project_data$ratio_PR_withTest_external <= 0.7,]$RatioPRsWithTests)

hist(project_data$CentralizedMngmtIndex)
hist(project_data$ModularityIndex)
hist(project_data$AdditiveContributionIndex)

hist(project_data$SocialConnections)
# hist(log(project_data[project_data$SocialConnections <= 0.05,]$SocialConnections + 1))
summary(project_data$SocialConnections)
table(project_data$SocialConnections > 0) # SocialConnections looks better as a binary variable
```


```{r eval=FALSE, collapse=TRUE, include=FALSE}
# Look for outliers in PR-level data

hist(pr_data$num_commit)
hist(log(pr_data[pr_data$num_commit <= 40,]$num_commit + 1))
summary(pr_data$Size)
hist(pr_data[pr_data$num_commit <= 40,]$Size)

hist(pr_data$ProjectAge)

hist(pr_data$GousiosHotness_partial)
hist(pr_data[pr_data$GousiosHotness_partial <= 200,]$GousiosHotness_partial)
hist(log(pr_data[pr_data$GousiosHotness_partial <= 200,]$GousiosHotness_partial + 1))
hist(pr_data[pr_data$GousiosHotness_partial <= 200,]$PRHotness)

table(pr_data$SubmitterPriorExperience)
summary(pr_data$MedianSubmitterExperience)
hist(pr_data$MedianSubmitterExperience)
hist(pr_data[pr_data$MedianSubmitterExperience <= 200,]$MedianSubmitterExperience) # better binary

table(pr_data$SocialConnections) # better binary
table(pr_data$SubmitterSocialConnections) # better binary

table(pr_data$HasTests)
```


Filter data based on outlier analysis:

```{r}
project_data.filtered = subset(project_data, 
                           num_forks < 25000
                           & size < 1500000
                           & hotness_mean_external_correct <= 50
                           & ratio_PR_withTest_external <= 0.7
                           & CentralizedMngmtIndex <= 0.5
                           & AdditiveContributionIndex <= 0.6
                           # & median_submitPR_exprience <= 20
                           # & num_closed_PR_external >= 43 # median across our data
                           # & num_closed_PR_external <= 12000
                           & RatioDuplicatePRs <= 0.1
                           )
```


###  Hypothesis: more modularity and centralized management -> higher PR merge ratio

```{r error=FALSE, message=FALSE, warning=FALSE}
model1 = glm(PRMergeRatio ~ 
               NumForks
             + Size
             + ProjectAge
             + SubmitterPriorExperience
             + SubmitterSocialConnections
             + PRHotness
             + RatioPRsWithTests
             + CentralizedMngmtIndex
             + ModularityIndex
             + AdditiveContributionIndex
             ,
             weights = NumPRs, 
             data = subset(project_data.filtered,
                           repoURL != "caskroom/homebrew-cask" # high-leverage point
                           & repoURL != "laravel/framework"
                           & repoURL != "nightscout/cgm-remote-monitor"
                           & repoURL != "rails/rails"
                           & repoURL != "cms-sw/cmssw"
                           & repoURL != "Homebrew/homebrew-core"
                          ),
             family = "binomial")

# multicollinearity
vif(model1)

# goodness of fit
pR2(model1)

# summary
summary(model1)

# effect size
anova(model1)
# Anova(model1, type="II")
a = Anova(model1, type="II")
# sum(a$`LR Chisq`, na.rm = TRUE)
# a/sum(a$`LR Chisq`, na.rm = TRUE)
round(a$`LR Chisq`/sum(a$`LR Chisq`, na.rm = TRUE),2)

# diagnostics
plot(model1)
```

```{r, include=FALSE}
if (REWRITE_MODELS){
  file="tex_model_merge_ratio.csv"
  modelNames=c("PR Merge Ratio")
  caption="External PR merge ratio model; response: PRMergeRatio"
  
  mList = list(m1=model1)
  makeTexRegCox(mList, file, modelNames, caption, digits=2)
  
  print_Anova_glm(model1, "anova_model_merge_ratio_1.csv")
}
```


```{r eval=FALSE, error=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Do the same at PR level (sanity check)
model1.pr = glm(isMerged ~ 
             + Size
             + ProjectAge
             + SubmitterPriorExperience
             + SubmitterSocialConnections
             + PRHotness
             + HasTests
             ,
             data = subset(pr_data, 
                           GousiosHotness_partial <= 200
                           & num_commit <= 40
                           & ProjectAge >= 1600 # Approximate Gousios 2013 data
                           ),
             family = "binomial")

vif(model1.pr)
pR2(model1.pr)
summary(model1.pr)
anova(model1.pr)
plot(model1.pr)
```


###  Hypothesis: more precommunication -> less duplication

```{r error=FALSE, message=FALSE, warning=FALSE}
model3 = glm(RatioDuplicatePRs ~
                    NumForks
                  + Size
                  + ProjectAge
                  + RatioPrecommunicatedPRs
                  ,
                  weights = NumPRs,
                  data = subset(project_data.filtered,
                                repoURL != "cms-sw/cmssw" # high-leverage point
                                & repoURL != "rails/rails" # high-leverage point
                                & repoURL != "symfony/symfony" # high-leverage point
                                & repoURL != "caskroom/homebrew-cask" # high-leverage point
                                ),
                  family = binomial("logit"))

vif(model3)
pR2(model3)
summary(model3)
anova(model3)
plot(model3)
# a = Anova(model3, type="II")
# round(a$`LR Chisq`/sum(a$`LR Chisq`, na.rm = TRUE),2)

```

```{r, include=FALSE}
if (REWRITE_MODELS){
  file="tex_model_duplicates.csv"
  modelNames=c("Duplicate ratio PRs")
  caption="Duplicates model"
  
  mList = list(m1=model3)
  makeTexRegCox(mList, file, modelNames, caption, digits=2)
  
  print_Anova_glm(model3, "anova_model_duplicates_1.csv")
}
```


### Hypothesis: higher easiness of changing code -> more forks attempting to merge

```{r error=FALSE, message=FALSE, warning=FALSE}
model4 = glm(ratio_fork_attemptContribute ~
               NumForks
             + Size
             + ProjectAge
             + CentralizedMngmtIndex
             + ModularityIndex
             + AdditiveContributionIndex
             ,
             weights = num_sampled_fork, 
             data = project_data.filtered, 
             family = "binomial")

vif(model4)
pR2(model4)
summary(model4)
anova(model4)
# Anova(model4, type="II")
# a = Anova(model4, type="II")
# sum(a$`LR Chisq`, na.rm = TRUE)
# round(a$`LR Chisq`/sum(a$`LR Chisq`, na.rm = TRUE),2)
plot(model4)

```

```{r, include=FALSE}
if (REWRITE_MODELS){
  file="tex_model_attempt_contribute.csv"
  modelNames=c("Forks submit PRs")
  caption="Attempt to contribute model; response: Ratio forks submitting PRs"
  
  mList = list(m1=model4)
  makeTexRegCox(mList, file, modelNames, caption, digits=2)
  
  print_Anova_glm(model4, "anova_model_attempt_contribute_1.csv")
}
```


### Hypothesis:  hard forks

```{r error=FALSE, message=FALSE, warning=FALSE}
model5 = glm(HasHardFork ~
                NumForks
              + Size
              + CentralizedMngmtIndex
              + ModularityIndex
              + AdditiveContributionIndex
              + PRMergeRatio
              ,
              data = project_data.filtered,
              family = "binomial")

vif(model5)
pR2(model5)
summary(model5)
anova(model5)
Anova(model5, type="II")
# a = anova(model5)
a = Anova(model5, type="II")
# sum(a$Deviance, na.rm = TRUE)
# a/sum(a$Deviance, na.rm = TRUE)
round(a$`LR Chisq`/sum(a$`LR Chisq`, na.rm = TRUE),2)
plot(model5)

```


```{r include=FALSE}
if (REWRITE_MODELS){
  file="tex_model_hard_forks.csv"
  modelNames=c("Hard forks")
  caption="Hard forks model; response: Has hard forks"
  
  mList = list(m1=model5)
  makeTexRegCox(mList, file, modelNames, caption, digits=2)
  
  print_Anova_glm(model5, "anova_model_hard_forks_1.csv")
}
```


